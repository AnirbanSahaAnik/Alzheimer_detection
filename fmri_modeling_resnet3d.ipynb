{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d76476b-5639-400c-9d10-97b0a9a86149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms.functional as TF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d036b7ea-5dce-4512-9604-3dcda320bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "fmri_root_folder = r'C:\\Users\\SAIFUL_BADHON\\Downloads\\fMRI\\output'  # Top-level folder containing subfolders\n",
    "csv_path = r'C:\\Users\\SAIFUL_BADHON\\Downloads\\fMRI_3_24_2025.csv'\n",
    "img_size = (64, 64, 64)\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0707285a-5995-43f4-a5e7-16c3c588cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load metadata\n",
    "df = pd.read_csv(csv_path)\n",
    "# label_encoder = LabelEncoder()\n",
    "# df['label'] = label_encoder.fit_transform(df['Group'])  # Converts Group to 0-5 labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9dd9c1a-5923-44bf-aee7-2ed13ff19c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label values: [1 0]\n"
     ]
    }
   ],
   "source": [
    "def check_valid_nii_exists(image_id, root_folder):\n",
    "    folder = os.path.join(root_folder, str(image_id))\n",
    "    if not os.path.isdir(folder):\n",
    "        return False\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith('.nii') or file.endswith('.nii.gz'):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df['has_file'] = df['Image Data ID'].apply(lambda x: check_valid_nii_exists(x, fmri_root_folder))\n",
    "df = df[df['has_file']].reset_index(drop=True)\n",
    "\n",
    "def map_to_binary(group):\n",
    "    if group in ['CN', 'SMC']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df['label'] = df['Group'].apply(map_to_binary)\n",
    "# # âœ… Step 2: Encode labels *after* filtering so they match the actual data\n",
    "# label_encoder = LabelEncoder()\n",
    "# df['label'] = label_encoder.fit_transform(df['Group'])\n",
    "\n",
    "# Debug check\n",
    "# print(\"Final label classes used:\", list(label_encoder.classes_))\n",
    "print(\"Encoded label values:\", df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e706326-4cc1-4755-801e-84c5e1d3e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "      <th>has_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1178798</td>\n",
       "      <td>007_S_6341</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>68</td>\n",
       "      <td>y1</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>6/11/2019</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I990573</td>\n",
       "      <td>007_S_6341</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>67</td>\n",
       "      <td>sc</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>4/30/2018</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I1327196</td>\n",
       "      <td>007_S_6310</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>70</td>\n",
       "      <td>y2</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>8/05/2020</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I974760</td>\n",
       "      <td>007_S_6255</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>75</td>\n",
       "      <td>sc</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>3/05/2018</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I1325573</td>\n",
       "      <td>007_S_6255</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>78</td>\n",
       "      <td>y2</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>7/27/2020</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>I243902</td>\n",
       "      <td>002_S_0685</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>95</td>\n",
       "      <td>v06</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Resting State fMRI</td>\n",
       "      <td>Original</td>\n",
       "      <td>7/08/2011</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>I1221056</td>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>90</td>\n",
       "      <td>y2</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>8/27/2019</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>I304790</td>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>82</td>\n",
       "      <td>v11</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Resting State fMRI</td>\n",
       "      <td>Original</td>\n",
       "      <td>5/15/2012</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>I240811</td>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>82</td>\n",
       "      <td>v06</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Resting State fMRI</td>\n",
       "      <td>Original</td>\n",
       "      <td>6/16/2011</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>I423209</td>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>84</td>\n",
       "      <td>v31</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Extended Resting State fMRI</td>\n",
       "      <td>Original</td>\n",
       "      <td>5/01/2014</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image Data ID     Subject Group Sex  Age Visit Modality  \\\n",
       "0        I1178798  007_S_6341   MCI   M   68    y1     fMRI   \n",
       "1         I990573  007_S_6341   MCI   M   67    sc     fMRI   \n",
       "2        I1327196  007_S_6310    CN   F   70    y2     fMRI   \n",
       "3         I974760  007_S_6255    CN   F   75    sc     fMRI   \n",
       "4        I1325573  007_S_6255    CN   F   78    y2     fMRI   \n",
       "..            ...         ...   ...  ..  ...   ...      ...   \n",
       "216       I243902  002_S_0685    CN   F   95   v06     fMRI   \n",
       "217      I1221056  002_S_0413    CN   F   90    y2     fMRI   \n",
       "218       I304790  002_S_0413    CN   F   82   v11     fMRI   \n",
       "219       I240811  002_S_0413    CN   F   82   v06     fMRI   \n",
       "220       I423209  002_S_0413    CN   F   84   v31     fMRI   \n",
       "\n",
       "                     Description      Type   Acq Date Format  Downloaded  \\\n",
       "0    Axial MB rsfMRI (Eyes Open)  Original  6/11/2019    DCM         NaN   \n",
       "1    Axial MB rsfMRI (Eyes Open)  Original  4/30/2018    DCM         NaN   \n",
       "2    Axial MB rsfMRI (Eyes Open)  Original  8/05/2020    DCM         NaN   \n",
       "3    Axial MB rsfMRI (Eyes Open)  Original  3/05/2018    DCM         NaN   \n",
       "4    Axial MB rsfMRI (Eyes Open)  Original  7/27/2020    DCM         NaN   \n",
       "..                           ...       ...        ...    ...         ...   \n",
       "216           Resting State fMRI  Original  7/08/2011    DCM         NaN   \n",
       "217  Axial MB rsfMRI (Eyes Open)  Original  8/27/2019    DCM         NaN   \n",
       "218           Resting State fMRI  Original  5/15/2012    DCM         NaN   \n",
       "219           Resting State fMRI  Original  6/16/2011    DCM         NaN   \n",
       "220  Extended Resting State fMRI  Original  5/01/2014    DCM         NaN   \n",
       "\n",
       "     has_file  label  \n",
       "0        True      1  \n",
       "1        True      1  \n",
       "2        True      0  \n",
       "3        True      0  \n",
       "4        True      0  \n",
       "..        ...    ...  \n",
       "216      True      0  \n",
       "217      True      0  \n",
       "218      True      0  \n",
       "219      True      0  \n",
       "220      True      0  \n",
       "\n",
       "[221 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6dc04c9-a23a-48ed-9bb2-35e445c3a5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group\n",
       "CN      104\n",
       "MCI      41\n",
       "LMCI     32\n",
       "EMCI     25\n",
       "AD       12\n",
       "SMC       7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdabdb15-2f85-4717-9c0f-b5c8e5a3467d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    111\n",
       "1    110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48a22087-4f85-4404-97f4-b6cfff841abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess fMRI images (4D -> 3D)\n",
    "def load_and_preprocess_nifti_from_folder(folder_path):\n",
    "    nii_file = None\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.nii') or file.endswith('.nii.gz'):\n",
    "            nii_file = os.path.join(folder_path, file)\n",
    "            break\n",
    "    if nii_file is None:\n",
    "        raise FileNotFoundError(f\"No NIfTI file found in {folder_path}\")\n",
    "    img = nib.load(nii_file)\n",
    "    data = img.get_fdata()\n",
    "    mean_3d = np.mean(data, axis=3)  # 4D -> 3D\n",
    "    return mean_3d\n",
    "\n",
    "def resize_volume(img, size=img_size):\n",
    "    import scipy.ndimage\n",
    "    zoom_factors = [s / float(img.shape[i]) for i, s in enumerate(size)]\n",
    "    return scipy.ndimage.zoom(img, zoom=zoom_factors, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aad8c7b5-08b2-4aaf-8427-784cb3a7dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: PyTorch Dataset\n",
    "class FMRIDataset(Dataset):\n",
    "    def __init__(self, dataframe, data_root, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = str(row['Image Data ID'])\n",
    "        label = int(row['label'])\n",
    "        folder_path = os.path.join(self.data_root, img_id)\n",
    "        volume = load_and_preprocess_nifti_from_folder(folder_path)\n",
    "        volume = resize_volume(volume)\n",
    "        volume = (volume - volume.mean()) / (volume.std() + 1e-5)\n",
    "        volume = np.expand_dims(volume, axis=0)  # Shape: (1, D, H, W)\n",
    "        return torch.tensor(volume, dtype=torch.float32), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2642474e-36c8-420e-aa1a-54aad72890cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train/test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "train_dataset = FMRIDataset(train_df, fmri_root_folder)\n",
    "test_dataset = FMRIDataset(test_df, fmri_root_folder)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0e73195-68f1-4db8-8e76-ab8dcb993edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "        self.downsample = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.downsample = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return self.relu(out + identity)\n",
    "\n",
    "class ResNet3D(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.layer1 = ResidualBlock3D(1, 16)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.layer2 = ResidualBlock3D(16, 32)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16 * 16, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.layer1(x))\n",
    "        x = self.pool2(self.layer2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c272c215-3a6f-4d5f-b855-10c3a5a178f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:17<00:00,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 8.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:11<00:00,  8.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 2.7773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:12<00:00,  8.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 1.5585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:15<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.7927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:16<00:00,  8.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.7737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:14<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 2.7789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:14<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 1.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:11<00:00,  8.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 0.7630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:19<00:00,  9.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 0.4919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:20<00:00,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 0.0686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet3D(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd92245a-acc8-44d7-bb51-40e8bbc49992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.48      0.61        23\n",
      "           1       0.62      0.91      0.74        22\n",
      "\n",
      "    accuracy                           0.69        45\n",
      "   macro avg       0.74      0.69      0.68        45\n",
      "weighted avg       0.74      0.69      0.67        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Report precision, recall, f1-score for each class\n",
    "\n",
    "report = classification_report(all_labels, all_preds)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a590dc04-809d-4117-a17d-501ac477ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GradCAM3D:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.hook_registered = False\n",
    "    #Registers forward and backward hooks on the last nn.Conv3d layer of the model.\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "            output.register_hook(self._backward_hook)\n",
    "\n",
    "        def backward_hook(grad):\n",
    "            self.gradients = grad.detach()\n",
    "\n",
    "        self._backward_hook = backward_hook\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv3d):  # Register on last Conv3D\n",
    "                last_conv = module\n",
    "        last_conv.register_forward_hook(forward_hook)\n",
    "        self.hook_registered = True\n",
    "\n",
    "    #Computes the Grad-CAM heatmap for a given input.\n",
    "    def generate(self, input_tensor, class_idx=None):\n",
    "        if not self.hook_registered:\n",
    "            self._register_hooks()\n",
    "\n",
    "        output = self.model(input_tensor)\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1).item()\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        output[0, class_idx].backward()\n",
    "\n",
    "        pooled_gradients = torch.mean(self.gradients, dim=[0, 2, 3, 4])  # [C]\n",
    "        activations = self.activations[0]  # [C, D, H, W]\n",
    "\n",
    "        # Avoid in-place ops\n",
    "        weighted_activations = activations * pooled_gradients.view(-1, 1, 1, 1)\n",
    "        heatmap = torch.mean(weighted_activations, dim=0).cpu().numpy()\n",
    "\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap) + 1e-8)\n",
    "        return heatmap\n",
    "\n",
    "    #Visualizes a slice of the Grad-CAM heatmap overlaid on the original 3D volume.\n",
    "    def overlay(self, input_volume, heatmap, slice_axis='axial', slice_idx=None, alpha=0.5):\n",
    "        # input_volume: shape (1, D, H, W)\n",
    "        input_volume = input_volume.squeeze(0)\n",
    "        if slice_axis == 'axial':\n",
    "            idx = slice_idx if slice_idx is not None else input_volume.shape[0] // 2\n",
    "            img_slice = input_volume[idx, :, :]\n",
    "            heat_slice = heatmap[idx, :, :]\n",
    "        elif slice_axis == 'coronal':  # y-plane\n",
    "            idx = slice_idx or input_volume.shape[1] // 2\n",
    "            img_slice = input_volume[:, idx, :]\n",
    "            heat_slice = heatmap[:, idx, :]\n",
    "        elif slice_axis == 'sagittal': # x-plane\n",
    "            idx = slice_idx or input_volume.shape[2] // 2\n",
    "            img_slice = input_volume[:, :, idx]\n",
    "            heat_slice = heatmap[:, :, idx]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid slice_axis. Choose from 'axial', 'coronal', 'sagittal'.\")\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img_slice, cmap='gray')\n",
    "        plt.imshow(heat_slice, cmap='jet', alpha=alpha)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        plt.savefig(f\"grad-cam{slice_axis}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d9833d-86f8-481b-8c89-9b65b2bdf975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nilearn in c:\\users\\saiful_badhon\\appdata\\roaming\\python\\python312\\site-packages (0.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nilearn) (1.4.2)\n",
      "Requirement already satisfied: lxml in c:\\programdata\\anaconda3\\lib\\site-packages (from nilearn) (5.2.1)\n",
      "Requirement already satisfied: nibabel>=5.2.0 in c:\\users\\saiful_badhon\\appdata\\roaming\\python\\python312\\site-packages (from nilearn) (5.3.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from nilearn) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from nilearn) (23.2)\n",
      "Requirement already satisfied: pandas>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nilearn) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nilearn) (2.32.2)\n",
      "Requirement already satisfied: scikit-learn>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nilearn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nilearn) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from nibabel>=5.2.0->nilearn) (4.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=2.2.0->nilearn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=2.2.0->nilearn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=2.2.0->nilearn) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.25.0->nilearn) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.25.0->nilearn) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.25.0->nilearn) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.25.0->nilearn) (2024.7.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.0->nilearn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nilearn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ebd531-b09b-441c-a578-293233ebe8f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Step 0: Set up model and Grad-CAM\u001b[39;00m\n\u001b[0;32m      9\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m model_cpu \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m model_cpu\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     12\u001b[0m gradcam \u001b[38;5;241m=\u001b[39m GradCAM3D(model_cpu)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import datasets\n",
    "from nilearn.image import resample_to_img\n",
    "\n",
    "# Step 0: Set up model and Grad-CAM\n",
    "device = torch.device(\"cpu\")\n",
    "model_cpu = model.to(device)\n",
    "model_cpu.eval()\n",
    "gradcam = GradCAM3D(model_cpu)\n",
    "\n",
    "# Step 1: Load Harvard-Oxford atlas (subcortical version, threshold = 0%)\n",
    "atlas = datasets.fetch_atlas_harvard_oxford('sub-maxprob-thr0-2mm')\n",
    "atlas_img = atlas.maps\n",
    "atlas_data = atlas_img.get_fdata()\n",
    "labels = atlas.labels\n",
    "\n",
    "# Optional: collect results\n",
    "results = []\n",
    "\n",
    "# Step 2: Loop through test set\n",
    "for idx, (inputs, labels_batch) in enumerate(tqdm(test_loader)):\n",
    "    for i in range(inputs.size(0)):\n",
    "        sample_input = inputs[i]         # [1, D, H, W]\n",
    "        sample_label = labels_batch[i].item()\n",
    "\n",
    "        # Prepare input tensor\n",
    "        input_tensor = sample_input.unsqueeze(0).to(device).float()\n",
    "\n",
    "        # Generate Grad-CAM heatmap\n",
    "        heatmap = gradcam.generate(input_tensor)\n",
    "\n",
    "        # Step 3: Wrap heatmap into dummy NIfTI image with identity affine\n",
    "        dummy_affine = np.eye(4)\n",
    "        heatmap_nii = nib.Nifti1Image(heatmap, affine=dummy_affine)\n",
    "\n",
    "        # Step 4: Resample to atlas space (MNI 2mm)\n",
    "        resampled_heatmap = resample_to_img(heatmap_nii, atlas_img, interpolation='nearest')\n",
    "        resampled_data = resampled_heatmap.get_fdata()\n",
    "\n",
    "        # Step 5: Get most activated voxel and its label\n",
    "        voxel_coords = np.unravel_index(np.argmax(resampled_data), resampled_data.shape)\n",
    "        label_idx = int(atlas_data[voxel_coords])\n",
    "\n",
    "        if label_idx < len(labels):\n",
    "            region = labels[label_idx]\n",
    "        else:\n",
    "            region = \"Unknown\"\n",
    "\n",
    "        #print(f\"Sample {idx}_{i} | True label: {sample_label} | Top region: {region}\")\n",
    "\n",
    "        # Optional: store in a list\n",
    "        results.append({\n",
    "            \"sample\": f\"{idx}_{i}\",\n",
    "            \"true_label\": sample_label,\n",
    "            \"region\": region,\n",
    "            \"voxel\": voxel_coords,\n",
    "            \"activation_score\": np.max(resampled_data)\n",
    "        })\n",
    "\n",
    "# Optional: save as CSV\n",
    "import pandas as pd\n",
    "pd.DataFrame(results).to_csv(\"gradcam_test_region_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c6c50-cb56-4276-adb3-a4a80679d479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
