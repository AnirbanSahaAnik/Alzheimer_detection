{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d76476b-5639-400c-9d10-97b0a9a86149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms.functional as TF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d036b7ea-5dce-4512-9604-3dcda320bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "fmri_root_folder = r'C:\\Users\\SAIFUL_BADHON\\Downloads\\fMRI\\output'  # Top-level folder containing subfolders\n",
    "csv_path = r'C:\\Users\\SAIFUL_BADHON\\Downloads\\fMRI_3_24_2025.csv'\n",
    "img_size = (64, 64, 64)\n",
    "batch_size = 8\n",
    "num_epochs = 50\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0707285a-5995-43f4-a5e7-16c3c588cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load metadata\n",
    "df = pd.read_csv(csv_path)\n",
    "# label_encoder = LabelEncoder()\n",
    "# df['label'] = label_encoder.fit_transform(df['Group'])  # Converts Group to 0-5 labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9dd9c1a-5923-44bf-aee7-2ed13ff19c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label values: [1 0]\n"
     ]
    }
   ],
   "source": [
    "def check_valid_nii_exists(image_id, root_folder):\n",
    "    folder = os.path.join(root_folder, str(image_id))\n",
    "    if not os.path.isdir(folder):\n",
    "        return False\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith('.nii') or file.endswith('.nii.gz'):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df['has_file'] = df['Image Data ID'].apply(lambda x: check_valid_nii_exists(x, fmri_root_folder))\n",
    "df = df[df['has_file']].reset_index(drop=True)\n",
    "\n",
    "def map_to_binary(group):\n",
    "    if group in ['CN', 'SMC']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df['label'] = df['Group'].apply(map_to_binary)\n",
    "# # âœ… Step 2: Encode labels *after* filtering so they match the actual data\n",
    "# label_encoder = LabelEncoder()\n",
    "# df['label'] = label_encoder.fit_transform(df['Group'])\n",
    "\n",
    "# Debug check\n",
    "# print(\"Final label classes used:\", list(label_encoder.classes_))\n",
    "print(\"Encoded label values:\", df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e706326-4cc1-4755-801e-84c5e1d3e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "      <th>has_file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1178798</td>\n",
       "      <td>007_S_6341</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>68</td>\n",
       "      <td>y1</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>6/11/2019</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I990573</td>\n",
       "      <td>007_S_6341</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>67</td>\n",
       "      <td>sc</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>4/30/2018</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I1327196</td>\n",
       "      <td>007_S_6310</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>70</td>\n",
       "      <td>y2</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>8/05/2020</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I974760</td>\n",
       "      <td>007_S_6255</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>75</td>\n",
       "      <td>sc</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>3/05/2018</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I1325573</td>\n",
       "      <td>007_S_6255</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>78</td>\n",
       "      <td>y2</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>7/27/2020</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>I243902</td>\n",
       "      <td>002_S_0685</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>95</td>\n",
       "      <td>v06</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Resting State fMRI</td>\n",
       "      <td>Original</td>\n",
       "      <td>7/08/2011</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>I1221056</td>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>90</td>\n",
       "      <td>y2</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Axial MB rsfMRI (Eyes Open)</td>\n",
       "      <td>Original</td>\n",
       "      <td>8/27/2019</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>I304790</td>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>82</td>\n",
       "      <td>v11</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Resting State fMRI</td>\n",
       "      <td>Original</td>\n",
       "      <td>5/15/2012</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>I240811</td>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>82</td>\n",
       "      <td>v06</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Resting State fMRI</td>\n",
       "      <td>Original</td>\n",
       "      <td>6/16/2011</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>I423209</td>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>84</td>\n",
       "      <td>v31</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Extended Resting State fMRI</td>\n",
       "      <td>Original</td>\n",
       "      <td>5/01/2014</td>\n",
       "      <td>DCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image Data ID     Subject Group Sex  Age Visit Modality  \\\n",
       "0        I1178798  007_S_6341   MCI   M   68    y1     fMRI   \n",
       "1         I990573  007_S_6341   MCI   M   67    sc     fMRI   \n",
       "2        I1327196  007_S_6310    CN   F   70    y2     fMRI   \n",
       "3         I974760  007_S_6255    CN   F   75    sc     fMRI   \n",
       "4        I1325573  007_S_6255    CN   F   78    y2     fMRI   \n",
       "..            ...         ...   ...  ..  ...   ...      ...   \n",
       "216       I243902  002_S_0685    CN   F   95   v06     fMRI   \n",
       "217      I1221056  002_S_0413    CN   F   90    y2     fMRI   \n",
       "218       I304790  002_S_0413    CN   F   82   v11     fMRI   \n",
       "219       I240811  002_S_0413    CN   F   82   v06     fMRI   \n",
       "220       I423209  002_S_0413    CN   F   84   v31     fMRI   \n",
       "\n",
       "                     Description      Type   Acq Date Format  Downloaded  \\\n",
       "0    Axial MB rsfMRI (Eyes Open)  Original  6/11/2019    DCM         NaN   \n",
       "1    Axial MB rsfMRI (Eyes Open)  Original  4/30/2018    DCM         NaN   \n",
       "2    Axial MB rsfMRI (Eyes Open)  Original  8/05/2020    DCM         NaN   \n",
       "3    Axial MB rsfMRI (Eyes Open)  Original  3/05/2018    DCM         NaN   \n",
       "4    Axial MB rsfMRI (Eyes Open)  Original  7/27/2020    DCM         NaN   \n",
       "..                           ...       ...        ...    ...         ...   \n",
       "216           Resting State fMRI  Original  7/08/2011    DCM         NaN   \n",
       "217  Axial MB rsfMRI (Eyes Open)  Original  8/27/2019    DCM         NaN   \n",
       "218           Resting State fMRI  Original  5/15/2012    DCM         NaN   \n",
       "219           Resting State fMRI  Original  6/16/2011    DCM         NaN   \n",
       "220  Extended Resting State fMRI  Original  5/01/2014    DCM         NaN   \n",
       "\n",
       "     has_file  label  \n",
       "0        True      1  \n",
       "1        True      1  \n",
       "2        True      0  \n",
       "3        True      0  \n",
       "4        True      0  \n",
       "..        ...    ...  \n",
       "216      True      0  \n",
       "217      True      0  \n",
       "218      True      0  \n",
       "219      True      0  \n",
       "220      True      0  \n",
       "\n",
       "[221 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6dc04c9-a23a-48ed-9bb2-35e445c3a5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group\n",
       "CN      104\n",
       "MCI      41\n",
       "LMCI     32\n",
       "EMCI     25\n",
       "AD       12\n",
       "SMC       7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdabdb15-2f85-4717-9c0f-b5c8e5a3467d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    111\n",
       "1    110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a22087-4f85-4404-97f4-b6cfff841abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess fMRI images (4D -> 3D)\n",
    "def load_and_preprocess_nifti_from_folder(folder_path):\n",
    "    nii_file = None\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.nii') or file.endswith('.nii.gz'):\n",
    "            nii_file = os.path.join(folder_path, file)\n",
    "            break\n",
    "    if nii_file is None:\n",
    "        raise FileNotFoundError(f\"No NIfTI file found in {folder_path}\")\n",
    "    img = nib.load(nii_file)\n",
    "    data = img.get_fdata()\n",
    "    mean_3d = np.mean(data, axis=3)  # 4D -> 3D\n",
    "    return mean_3d\n",
    "\n",
    "def resize_volume(img, size=img_size):\n",
    "    import scipy.ndimage\n",
    "    zoom_factors = [s / float(img.shape[i]) for i, s in enumerate(size)]\n",
    "    return scipy.ndimage.zoom(img, zoom=zoom_factors, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aad8c7b5-08b2-4aaf-8427-784cb3a7dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: PyTorch Dataset\n",
    "class FMRIDataset(Dataset):\n",
    "    def __init__(self, dataframe, data_root, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = str(row['Image Data ID'])\n",
    "        label = int(row['label'])\n",
    "        folder_path = os.path.join(self.data_root, img_id)\n",
    "        volume = load_and_preprocess_nifti_from_folder(folder_path)\n",
    "        volume = resize_volume(volume)\n",
    "        volume = (volume - volume.mean()) / (volume.std() + 1e-5)\n",
    "        volume = np.expand_dims(volume, axis=0)  # Shape: (1, D, H, W)\n",
    "        return torch.tensor(volume, dtype=torch.float32), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2642474e-36c8-420e-aa1a-54aad72890cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train/test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "train_dataset = FMRIDataset(train_df, fmri_root_folder)\n",
    "test_dataset = FMRIDataset(test_df, fmri_root_folder)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0e73195-68f1-4db8-8e76-ab8dcb993edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN3DEncoder(nn.Module):\n",
    "    def __init__(self, output_size=128):\n",
    "        super(CNN3DEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 8, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.conv2 = nn.Conv3d(8, 16, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(16 * 16 * 16 * 16, output_size)  # Adjust if your input volume shape changes\n",
    "\n",
    "    def forward(self, x):  # x: [B, 1, D, H, W]\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x  # [B, output_size]\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, cnn_embed_dim=128, lstm_hidden_dim=64, num_layers=1, num_classes=2):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.cnn_encoder = CNN3DEncoder(output_size=cnn_embed_dim)\n",
    "        self.lstm = nn.LSTM(input_size=cnn_embed_dim,\n",
    "                            hidden_size=lstm_hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):  # x: [B, T, 1, D, H, W]\n",
    "        batch_size, T, C, D, H, W = x.size()\n",
    "        x = x.view(batch_size * T, C, D, H, W)\n",
    "        cnn_features = self.cnn_encoder(x)  # [B*T, cnn_embed_dim]\n",
    "        cnn_features = cnn_features.view(batch_size, T, -1)  # [B, T, cnn_embed_dim]\n",
    "        lstm_out, _ = self.lstm(cnn_features)  # [B, T, lstm_hidden_dim]\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Use the last time step\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c272c215-3a6f-4d5f-b855-10c3a5a178f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|                                                                               | 0/22 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 32\u001b[0m, in \u001b[0;36mCNN_LSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):  \u001b[38;5;66;03m# x: [B, T, 1, D, H, W]\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     batch_size, T, C, D, H, W \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m     33\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size \u001b[38;5;241m*\u001b[39m T, C, D, H, W)\n\u001b[0;32m     34\u001b[0m     cnn_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_encoder(x)  \u001b[38;5;66;03m# [B*T, cnn_embed_dim]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 5)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN_LSTM(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd92245a-acc8-44d7-bb51-40e8bbc49992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.49      1.00      0.66        22\n",
      "\n",
      "    accuracy                           0.49        45\n",
      "   macro avg       0.24      0.50      0.33        45\n",
      "weighted avg       0.24      0.49      0.32        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Report precision, recall, f1-score for each class\n",
    "\n",
    "report = classification_report(all_labels, all_preds)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590dc04-809d-4117-a17d-501ac477ff90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
